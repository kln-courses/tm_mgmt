# From Text Analysis to Actionable Knowledge: Data-intensive Methods for Unstructured and Text-heavy Data

```yaml
Date: Tuesday, November 29,
Time: 10:00-14:00
Location: 1324, 025, Tvillingeauditorium
```
### Speaker
Hilke Reckman (HR), Morten H.J. Fenger (MHJF), Kristoffer L. Nielbo (KLN),

### Program

| Time        | Title           | Speaker |
| ------------- |:-------------:| -----:|
| 10:00-10:30 | Text Analytics | KLN |
| 10:30-11:00 | Division of Labor and NLP | HR |
| 11:30-12:00 | Models and Algorithms #1 | HR/KLN |
| 12:00-12:30 | Lunch| |
| 12:30-13:00 | Models and Algorithms #2 | KLN |
| 13:00-13:30 | Applied Text Mining | MHJF |
| 13:30-14:00 | General Discussion| KLN/MHJF |  


### Keywords
`text analytics`, `business intelligence`,
`language representations`,`data preparation`,
`sentiment analysis`,`latent variables`, `classification`,`clustering`
`resources and tools`, `division of labor`, `domain knowledge`


## Detailed Program

### Text Analytics ###
Text analytics (~ text mining) is a heterogeneous research field that focuses on extraction of meaningful patterns from unstructured and text-heavy data. The meaningful patterns are typically extracted by applying machine learning to target data sets from large non-relational databases. In this presentation, we will take a look at the composition of text analytics, its generic pipeline, and its potential for social science and humanities (SSH) research.
### Models and Algorithms \#1 ###
Natural language is fundamentally qualitative and lacks the kind of structure (or model) required by large-scale automated analysis. In order to apply methods from text analytics to natural language data, it is therefore necessary to create a quantitative language model. Such language models typically rely on word probabilities and their co-occurrence structure. In this presentation, we will go through some of the most common language models and simple algorithms for extracting meaningful patterns form word probabilities.  
### Models and Algorithms \#2 ###
Text analytics relies heavily on techniques from machine learning for macro-level document analysis. Machine learning offers a range of techniques for organizing documents according to latent patterns or metadata. An important distinction is between techniques for unsupervised learning, which find grouping in the data independent of previous knowledge, and supervised learning, which maps a set of documents to preexisting classes. In this presentation, we will look at unsupervised learning (clustering and topic modeling) and supervised learning (classifications) and, finally, discuss how to combine these machine learning techniques in SSH research.


## Biographies
**HR** is a computational semanticist interested in how people understand language, and try to investigate this through computational modeling. HR is particularly interested in the relation between language and thought, or reasoning, and in how languages are learned in the first place: How do language learners figure out what the people around them are trying to say, and how do they learn to formulate their own messages about the world? The computational approach allows for experimenting with different mechanisms, datasets, and prior knowledge and assumptions in order to get a better understanding of what is minimally needed for language acquisition. Computational models of how people deal with language also have the potential to lead to interesting applications where computers use human language more intelligently than they do now.  

**MHJF**  

**KLN** is a humanist scholar with specialization in computational and quantitative methods for analysis, interpretation and storage of cultural data. He has participated in a range of collaborative and interdisciplinary research projects involving researchers from the humanities, social sciences, health science, and natural sciences. His research covers two broad areas: automated text analysis and modeling of cultural behavior. Both areas explore the cultural information space in new and innovative ways by combining cultural data and humanities theories with statistics, computer algorithms, and visualization.
